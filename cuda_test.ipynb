{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Check if container is passing through + general imports \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Databricks Connection and Creating Dataset from Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------+-----------+-----------+----------+----------+---------+-------------------+---------+----------------+----------------+----------+----------------+--------------+\n",
      "|ss_sold_date_sk|ss_item_sk|ss_store_sk|ss_promo_sk|ss_quantity|    d_date|d_day_name|d_holiday|d_following_holiday|d_weekend|       i_item_id|      s_store_id|p_promo_id|promo_start_date|promo_end_date|\n",
      "+---------------+----------+-----------+-----------+-----------+----------+----------+---------+-------------------+---------+----------------+----------------+----------+----------------+--------------+\n",
      "|        2451181|     14386|          1|        251|         77|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAACDIDAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     11323|          1|          1|         84|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAALDMCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     10141|          1|         44|         96|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAANJHCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      8059|          1|         72|         51|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAALHPBAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      7508|          1|         36|         96|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAEFNBAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     11696|          1|        242|         38|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAALNCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      2545|          1|        260|          7|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAABPJAAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      5708|          1|          2|         56|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAMEGBAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      7388|          1|        205|          7|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAMNMBAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      5464|          1|        216|         69|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAIFFBAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      8512|          1|        186|         47|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAAEBCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|       838|          1|         20|         82|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAGEDAAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     10832|          1|        191|         64|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAAFKCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      8972|          1|        244|         35|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAMADCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      8774|          1|        181|         73|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAGECCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     10496|          1|         49|         98|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAAAJCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      8743|          1|        156|         85|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAHCCCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     11215|          1|         40|        100|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAPMLCAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|      2083|          1|        210|         61|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAADCIAAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "|        2451181|     15322|          1|        168|         74|1999-01-02|  Saturday|        N|                  Y|        Y|AAAAAAAAKNLDAAAA|AAAAAAAABAAAAAAA|      NULL|            NULL|          NULL|\n",
      "+---------------+----------+-----------+-----------+-----------+----------+----------+---------+-------------------+---------+----------------+----------------+----------+----------------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Make Connection\n",
    "from databricks_connect import connect_explicit\n",
    "spark = connect_explicit()\n",
    "\n",
    "#Making initial data query\n",
    "data = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        ss_sold_date_sk,\n",
    "        ss_item_sk,\n",
    "        ss_store_sk,\n",
    "        ss_promo_sk,\n",
    "        ss_quantity,\n",
    "        d_date,\n",
    "        d_day_name,\n",
    "        d_holiday,\n",
    "        d_following_holiday,\n",
    "        d_weekend,\n",
    "        i_item_id,\n",
    "        s_store_id\n",
    "        \n",
    "    FROM samples.tpcds_sf1.store_sales AS ss\n",
    "    INNER JOIN samples.tpcds_sf1.date_dim AS dd\n",
    "    ON ss.ss_sold_date_sk = dd.d_date_sk\n",
    "    INNER JOIN samples.tpcds_sf1.item AS i\n",
    "    ON ss.ss_item_sk = i.i_item_sk\n",
    "    INNER JOIN samples.tpcds_sf1.store AS s\n",
    "    ON ss.ss_store_sk = s.s_store_sk\n",
    "    \"\"\")\n",
    "\n",
    "# Promotion table with actual dates\n",
    "promo = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        p.p_item_sk, \n",
    "        p.p_promo_sk,\n",
    "        p.p_promo_id,\n",
    "        dd_start.d_date as promo_start_date,\n",
    "        dd_end.d_date as promo_end_date\n",
    "\n",
    "    FROM samples.tpcds_sf1.promotion AS p\n",
    "    LEFT JOIN samples.tpcds_sf1.date_dim AS dd_start\n",
    "    ON p.p_start_date_sk = dd_start.d_date_sk\n",
    "    LEFT JOIN samples.tpcds_sf1.date_dim AS dd_end\n",
    "    ON p.p_end_date_sk = dd_end.d_date_sk\n",
    "    \"\"\")\n",
    "\n",
    "sales_promo = data.join(\n",
    "    promo,\n",
    "    (data.ss_item_sk == promo.p_item_sk) & \n",
    "    (data.d_date >= promo.promo_start_date) & \n",
    "    (data.d_date <= promo.promo_end_date),\n",
    "    \"left\"\n",
    ").select(\n",
    "    data[\"*\"],\n",
    "    promo.p_promo_id,\n",
    "    promo.promo_start_date,\n",
    "    promo.promo_end_date\n",
    ")\n",
    "\n",
    "sales_promo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+-------+-----------------+-------+----------------+----------------+---------------+--------+-----------+---------+\n",
      "|      date|quantity|     day|holiday|following_holiday|weekend|         item_id|        store_id|promo_indicator|promo_id|promo_start|promo_end|\n",
      "+----------+--------+--------+-------+-----------------+-------+----------------+----------------+---------------+--------+-----------+---------+\n",
      "|1999-01-02|    77.0|Saturday|      N|                Y|      Y|AAAAAAAACDIDAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    84.0|Saturday|      N|                Y|      Y|AAAAAAAALDMCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    96.0|Saturday|      N|                Y|      Y|AAAAAAAANJHCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    51.0|Saturday|      N|                Y|      Y|AAAAAAAALHPBAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    96.0|Saturday|      N|                Y|      Y|AAAAAAAAEFNBAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    38.0|Saturday|      N|                Y|      Y|AAAAAAAAALNCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|     7.0|Saturday|      N|                Y|      Y|AAAAAAAABPJAAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    56.0|Saturday|      N|                Y|      Y|AAAAAAAAMEGBAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|     7.0|Saturday|      N|                Y|      Y|AAAAAAAAMNMBAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    69.0|Saturday|      N|                Y|      Y|AAAAAAAAIFFBAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    47.0|Saturday|      N|                Y|      Y|AAAAAAAAAEBCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    82.0|Saturday|      N|                Y|      Y|AAAAAAAAGEDAAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    64.0|Saturday|      N|                Y|      Y|AAAAAAAAAFKCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    35.0|Saturday|      N|                Y|      Y|AAAAAAAAMADCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    73.0|Saturday|      N|                Y|      Y|AAAAAAAAGECCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    98.0|Saturday|      N|                Y|      Y|AAAAAAAAAAJCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    85.0|Saturday|      N|                Y|      Y|AAAAAAAAHCCCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|   100.0|Saturday|      N|                Y|      Y|AAAAAAAAPMLCAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    61.0|Saturday|      N|                Y|      Y|AAAAAAAADCIAAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "|1999-01-02|    74.0|Saturday|      N|                Y|      Y|AAAAAAAAKNLDAAAA|AAAAAAAABAAAAAAA|              N|    NULL|       NULL|     NULL|\n",
      "+----------+--------+--------+-------+-----------------+-------+----------------+----------------+---------------+--------+-----------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#Clean and aggregate data\n",
    "#spc = \"Sales Promo Cleaned\"\n",
    "\n",
    "from pyspark.sql.functions import sum as spark_sum, when, col\n",
    "from pyspark.sql.types import DateType, StringType, FloatType\n",
    "\n",
    "spc = sales_promo.select(               sales_promo.d_date,\n",
    "                                        sales_promo.ss_quantity, \n",
    "                                        sales_promo.d_day_name,\n",
    "                                        sales_promo.d_holiday,\n",
    "                                        sales_promo.d_following_holiday,\n",
    "                                        sales_promo.d_weekend,\n",
    "                                        sales_promo.i_item_id,\n",
    "                                        sales_promo.s_store_id,\n",
    "                                        sales_promo.p_promo_id,\n",
    "                                        sales_promo.promo_start_date,\n",
    "                                        sales_promo.promo_end_date)\n",
    "\n",
    "spc = spc.withColumn(\n",
    "    \"promo_indicator\", \n",
    "        when(col(\"p_promo_id\").isNotNull(), \"Y\").otherwise(\"N\")\n",
    ")\n",
    "\n",
    "spc_typed = spc.select(\n",
    "    col(\"d_date\").cast(DateType()).alias(\"date\"),\n",
    "    col(\"ss_quantity\").cast(FloatType()).alias(\"quantity\"),\n",
    "    col(\"d_day_name\").cast(StringType()).alias(\"day\"),\n",
    "    col(\"d_holiday\").cast(StringType()).alias(\"holiday\"),\n",
    "    col(\"d_following_holiday\").cast(StringType()).alias(\"following_holiday\"),\n",
    "    col(\"d_weekend\").cast(StringType()).alias(\"weekend\"),\n",
    "    col(\"i_item_id\").cast(StringType()).alias(\"item_id\"),\n",
    "    col(\"s_store_id\").cast(StringType()).alias(\"store_id\"),\n",
    "    col(\"promo_indicator\").cast(StringType()).alias(\"promo_indicator\"),\n",
    "    col(\"p_promo_id\").cast(StringType()).alias(\"promo_id\"),\n",
    "    col(\"promo_start_date\").cast(DateType()).alias(\"promo_start\"),\n",
    "    col(\"promo_end_date\").cast(DateType()).alias(\"promo_end\")\n",
    ")\n",
    "\n",
    "spc_typed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+-------+-----------------+-------+----------------+----------------+---------------+\n",
      "|      date|quantity|   day|holiday|following_holiday|weekend|         item_id|        store_id|promo_indicator|\n",
      "+----------+--------+------+-------+-----------------+-------+----------------+----------------+---------------+\n",
      "|1998-01-02|    84.0|Friday|      N|                Y|      Y|AAAAAAAAEAKDAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    86.0|Friday|      N|                Y|      Y|AAAAAAAAMDACAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    48.0|Friday|      N|                Y|      Y|AAAAAAAADNJAAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    36.0|Friday|      N|                Y|      Y|AAAAAAAALHFCAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    44.0|Friday|      N|                Y|      Y|AAAAAAAACCGEAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    17.0|Friday|      N|                Y|      Y|AAAAAAAAEAJBAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    25.0|Friday|      N|                Y|      Y|AAAAAAAAEIDCAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    26.0|Friday|      N|                Y|      Y|AAAAAAAAPDHDAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    72.0|Friday|      N|                Y|      Y|AAAAAAAAKDCEAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    48.0|Friday|      N|                Y|      Y|AAAAAAAACGNCAAAA|AAAAAAAAIAAAAAAA|              N|\n",
      "|1998-01-02|    58.0|Friday|      N|                Y|      Y|AAAAAAAACBEAAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    88.0|Friday|      N|                Y|      Y|AAAAAAAACMLBAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    54.0|Friday|      N|                Y|      Y|AAAAAAAAKPDDAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    69.0|Friday|      N|                Y|      Y|AAAAAAAAGKNCAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    68.0|Friday|      N|                Y|      Y|AAAAAAAAFCADAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    66.0|Friday|      N|                Y|      Y|AAAAAAAAABMBAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    59.0|Friday|      N|                Y|      Y|AAAAAAAAGEKAAAAA|AAAAAAAAIAAAAAAA|              N|\n",
      "|1998-01-02|    NULL|Friday|      N|                Y|      Y|AAAAAAAANJPAAAAA|AAAAAAAAHAAAAAAA|              N|\n",
      "|1998-01-02|    18.0|Friday|      N|                Y|      Y|AAAAAAAAECPBAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "|1998-01-02|    NULL|Friday|      N|                Y|      Y|AAAAAAAACGOBAAAA|AAAAAAAABAAAAAAA|              N|\n",
      "+----------+--------+------+-------+-----------------+-------+----------------+----------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "spc_typed_cleaned = spc_typed.select(\n",
    "    col(\"date\"),\n",
    "    col(\"quantity\"),\n",
    "    col(\"day\"),\n",
    "    col(\"holiday\"),\n",
    "    col(\"following_holiday\"),\n",
    "    col(\"weekend\"),\n",
    "    col(\"item_id\"),\n",
    "    col(\"store_id\"),\n",
    "    col(\"promo_indicator\")\n",
    ").sort(asc(\"date\"))\n",
    "\n",
    "spc_typed_cleaned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Preparation and Cleaning in Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>day</th>\n",
       "      <th>holiday</th>\n",
       "      <th>following_holiday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>promo_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>AAAAAAAAEAJBAAAA</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>AAAAAAAAMDACAAAA</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>AAAAAAAADNJAAAAA</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>AAAAAAAAEAKDAAAA</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>AAAAAAAAECPBAAAA</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           item_id          store_id  quantity     day holiday  \\\n",
       "0  1998-01-02  AAAAAAAAEAJBAAAA  AAAAAAAABAAAAAAA      17.0  Friday       N   \n",
       "1  1998-01-02  AAAAAAAAMDACAAAA  AAAAAAAABAAAAAAA      86.0  Friday       N   \n",
       "2  1998-01-02  AAAAAAAADNJAAAAA  AAAAAAAABAAAAAAA      48.0  Friday       N   \n",
       "3  1998-01-02  AAAAAAAAEAKDAAAA  AAAAAAAABAAAAAAA      84.0  Friday       N   \n",
       "4  1998-01-02  AAAAAAAAECPBAAAA  AAAAAAAABAAAAAAA      18.0  Friday       N   \n",
       "\n",
       "  following_holiday weekend promo_indicator  \n",
       "0                 Y       Y               N  \n",
       "1                 Y       Y               N  \n",
       "2                 Y       Y               N  \n",
       "3                 Y       Y               N  \n",
       "4                 Y       Y               N  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spc_typed_cleaned.toPandas()\n",
    "df = df.dropna()\n",
    "df_qty = df[[\"date\",\"item_id\",\"store_id\",\"quantity\"]]\n",
    "df_str = df[[\"date\", \"item_id\", \"store_id\", \"day\", \"holiday\", \"following_holiday\", \"weekend\", \"promo_indicator\"]].drop_duplicates()\n",
    "df_str = df_str.set_index([\"date\",\"item_id\",\"store_id\"])\n",
    "df_qty = df_qty.groupby([\"date\", \"item_id\", \"store_id\"]).sum()\n",
    "df = df_qty.join(df_str,on = [\"date\", \"item_id\", \"store_id\"], how = \"right\").reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2608127 entries, 0 to 2608126\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   date               object \n",
      " 1   item_id            object \n",
      " 2   store_id           object \n",
      " 3   quantity           float32\n",
      " 4   day                object \n",
      " 5   holiday            object \n",
      " 6   following_holiday  object \n",
      " 7   weekend            object \n",
      " 8   promo_indicator    object \n",
      "dtypes: float32(1), object(8)\n",
      "memory usage: 169.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Items: 9000\n",
      "Unique Stores: 6\n",
      "Unique Dates: 2608127\n",
      "RangeIndex(start=0, stop=2608127, step=1)\n",
      "['date', 'item_id', 'store_id', 'quantity', 'day', 'holiday', 'following_holiday', 'weekend', 'promo_indicator']\n",
      "[datetime.date(1998, 1, 2) datetime.date(1998, 1, 3)\n",
      " datetime.date(1998, 1, 4) ... datetime.date(2002, 12, 31)\n",
      " datetime.date(2003, 1, 1) datetime.date(2003, 1, 2)]\n",
      "['AAAAAAAAEAJBAAAA' 'AAAAAAAAMDACAAAA' 'AAAAAAAADNJAAAAA' ...\n",
      " 'AAAAAAAAJOLDAAAA' 'AAAAAAAACENAAAAA' 'AAAAAAAAOLPAAAAA']\n",
      "['AAAAAAAABAAAAAAA' 'AAAAAAAAHAAAAAAA' 'AAAAAAAAIAAAAAAA'\n",
      " 'AAAAAAAACAAAAAAA' 'AAAAAAAAKAAAAAAA' 'AAAAAAAAEAAAAAAA']\n",
      "[ 17.  86.  48.  84.  18.  25.  72.  58.  44.  88.  54.  69.  26.  66.\n",
      "  68.  36.  59.  87.   2. 100.   3.  55.  34.  37.  89.  24.  61.  62.\n",
      "  96.  76.  70.  95.  63.  94.  82.  42.  33.  19.  16.  90.  75.  28.\n",
      "  74.  38.  57.  65.  14.  40.  71.  21.   1.  39.  43.  78.  93.   6.\n",
      "  79.  81.   4.  60.  52.  77.  15.  47.  56.  67.  35.   9.  30.  31.\n",
      "  92.  49.  11.  41.  51.  27.  29.  97.  20.  83.  45.  23.  13.  91.\n",
      "  99.   7.   8.  53.  73.  12.  22.  46.  85.  50.   5.  32.  98.  80.\n",
      "  64.  10. 118. 179. 155. 165. 149. 150. 110. 159. 120. 107. 135. 126.\n",
      " 124. 123. 151. 119. 111. 178. 141. 101. 117. 170. 131. 121. 171. 157.\n",
      " 122. 177. 152. 176. 136. 156. 112. 146. 103. 168. 175. 186. 105. 167.\n",
      " 108. 115. 109. 132. 163. 128. 144. 138. 130. 114. 164. 153. 113. 125.\n",
      " 139. 148. 116. 142. 133. 154. 102. 127. 106. 143. 145. 129. 147. 134.\n",
      " 104. 182. 183. 161. 162. 137. 172. 140. 187. 192. 158. 199. 160. 174.\n",
      " 185. 169. 166. 173. 181. 194. 184. 191. 180. 197. 246. 189. 188. 190.\n",
      " 200. 260. 195. 196. 208. 262. 198. 220. 217. 231. 238. 227. 202. 206.\n",
      " 214. 247. 193. 211. 215. 237. 213. 216. 228. 207. 219. 225. 204. 233.\n",
      " 257. 205. 222. 209. 229. 239. 235. 307. 224. 212. 223. 274. 230. 203.\n",
      " 251. 245. 242. 221. 226. 253. 288. 234. 283. 255. 261. 201. 256. 232.]\n",
      "['Friday' 'Saturday' 'Sunday' 'Monday' 'Tuesday' 'Wednesday' 'Thursday']\n",
      "['N' 'Y']\n",
      "['Y' 'N']\n",
      "['Y' 'N']\n",
      "['N' 'Y']\n"
     ]
    }
   ],
   "source": [
    "unique_items = df[\"item_id\"].nunique()\n",
    "print(f\"Unique Items: {unique_items}\")\n",
    "unique_stores = df[\"store_id\"].nunique()\n",
    "print(f\"Unique Stores: {unique_stores}\")\n",
    "unique_dates = df.index.nunique()\n",
    "print(f\"Unique Dates: {unique_dates}\")\n",
    "print(df.index.unique())\n",
    "\n",
    "columns = df.columns.to_list()\n",
    "print(columns)\n",
    "\n",
    "for column in columns:\n",
    "    print(df[column].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-container-template-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
